{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 0A: Setup - Install Libraries\n",
    "%pip install folium geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 0B: Setup - Import Libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1A: Load Dataset\n",
    "# Display 2 sample DataFrame rows\n",
    "noscemus_metadata = pd.read_csv(\"https://raw.githubusercontent.com/CCS-ZCU/noscemus_ETF/refs/heads/master/data/metadata_table_long.csv\")\n",
    "noscemus_metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1B: Inspect DataFrame Structure\n",
    "# Display DataFrame Columns\n",
    "\n",
    "print(\"\\nColumns in noscemus_metadata:\")\n",
    "print(noscemus_metadata.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1C: Examine 'Place' Column\n",
    "# Inspect Potential Columns\n",
    "# Replace 'candidate_column_name' with a column name from the list above\n",
    "candidate_column_name = 'Place' # <-- CHANGE THIS VALUE \n",
    "\n",
    "if candidate_column_name in noscemus_metadata.columns:\n",
    "    print(f\"\\nUnique values in '{candidate_column_name}':\")\n",
    "    # Display a sample of unique values and their counts\n",
    "    print(noscemus_metadata[candidate_column_name].value_counts().head(30))\n",
    "    print(f\"\\nNumber of unique values in '{candidate_column_name}': {noscemus_metadata[candidate_column_name].nunique()}\")\n",
    "    print(f\"Number of missing values in '{candidate_column_name}': {noscemus_metadata[candidate_column_name].isnull().sum()}\")\n",
    "    # Show some raw examples of the data in this column\n",
    "    print(\"\\nSample raw entries (up to first 20 non-null):\")\n",
    "    print(noscemus_metadata[candidate_column_name].dropna().head(20).tolist())\n",
    "else:\n",
    "    print(f\"Column '{candidate_column_name}' not found in DataFrame. Please choose from the list printed above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2A: Define Place Splitting Logic and Expand Rows\n",
    "\n",
    "def split_places(place_string):\n",
    "    if pd.isna(place_string) or not isinstance(place_string, str):\n",
    "        return [] # Return empty list for NaN or non-string input\n",
    "    # Split by comma, semicolon, or ampersand. Also handle cases like 'Place1 / Place2'.\n",
    "    # Regex looks for one or more delimiters, surrounded by optional whitespace.\n",
    "    places = re.split(r'\\s*[,;&/]\\s*', place_string)\n",
    "    # Clean up each individual place name: strip whitespace, remove empty strings\n",
    "    return [p.strip() for p in places if p and p.strip()] \n",
    "\n",
    "expanded_rows = []\n",
    "if 'noscemus_metadata' in locals():\n",
    "    print(f\"Original number of rows in noscemus_metadata: {len(noscemus_metadata)}\")\n",
    "    for index, row in noscemus_metadata.iterrows():\n",
    "        original_place_entry = row['Place']\n",
    "        individual_places = split_places(original_place_entry)\n",
    "        \n",
    "        if not individual_places: # Handles NaN, empty strings, or strings that become empty after split\n",
    "            # Keep the row as is, but ensure 'Place' is None or a consistent empty marker if it was NaN/empty\n",
    "            new_row = row.copy()\n",
    "            new_row['Place'] = None # Or np.nan, or an empty string, depending on desired handling for mapping\n",
    "            expanded_rows.append(new_row)\n",
    "        elif len(individual_places) == 1:\n",
    "            # Single place, just copy the row with the cleaned single place name\n",
    "            new_row = row.copy()\n",
    "            new_row['Place'] = individual_places[0]\n",
    "            expanded_rows.append(new_row)\n",
    "        else:\n",
    "            # Multiple places, create a new row for each\n",
    "            for place_name in individual_places:\n",
    "                new_row = row.copy()\n",
    "                new_row['Place'] = place_name\n",
    "                # Add original multi-place string for reference if needed\n",
    "                new_row['Original_Multi_Place_Entry'] = original_place_entry \n",
    "                expanded_rows.append(new_row)\n",
    "    \n",
    "    expanded_noscemus_metadata = pd.DataFrame(expanded_rows)\n",
    "    print(f\"Number of rows after expansion: {len(expanded_noscemus_metadata)}\")\n",
    "\n",
    "    # Display a sample, especially focusing on some known multi-place entries to verify\n",
    "    print(\"\\nSample of expanded_noscemus_metadata (showing some original multi-place entries):\")\n",
    "    # Example: Find rows originating from 'Liegnitz, Wrocław' if it exists\n",
    "    if 'Original_Multi_Place_Entry' in expanded_noscemus_metadata.columns:\n",
    "        sample_multi = expanded_noscemus_metadata[expanded_noscemus_metadata['Original_Multi_Place_Entry'] == 'Liegnitz, Wrocław']\n",
    "        if not sample_multi.empty:\n",
    "            print(sample_multi[['id', 'Full title', 'Place', 'Original_Multi_Place_Entry']].head())\n",
    "        else:\n",
    "            print(\"Could not find 'Liegnitz, Wrocław' in Original_Multi_Place_Entry for sample.\")\n",
    "        # Show general head as well\n",
    "        print(\"\\nGeneral head of expanded data:\")\n",
    "        print(expanded_noscemus_metadata[['id', 'Full title', 'Place', 'Original_Multi_Place_Entry' if 'Original_Multi_Place_Entry' in expanded_noscemus_metadata.columns else 'Place']].head())\n",
    "    else:\n",
    "        print(\"\\nGeneral head of expanded data (Original_Multi_Place_Entry column not created, likely no multi-place entries found):\")\n",
    "        print(expanded_noscemus_metadata[['id', 'Full title', 'Place']].head())\n",
    "else:\n",
    "    print(\"Error: noscemus_metadata DataFrame not found. Please load it first.\")\n",
    "    expanded_noscemus_metadata = pd.DataFrame() # Initialize empty to avoid errors later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2B: Extract Unique Place Names for Geocoding\n",
    "# Ensure 'expanded_noscemus_metadata' is available and populated from the previous cell.\n",
    "if 'expanded_noscemus_metadata' in locals() and not expanded_noscemus_metadata.empty:\n",
    "    actual_publication_place_column = 'Place' # This is the column with individual place names\n",
    "    places_series = expanded_noscemus_metadata[actual_publication_place_column].astype(str).str.strip()\n",
    "    unique_raw_places = places_series.dropna().unique() # Important to dropna here\n",
    "    print(f\"Found {len(unique_raw_places)} unique raw place mentions from '{actual_publication_place_column}' in the expanded data.\")\n",
    "    print(\"Sample of raw places (first 50 from expanded data):\")\n",
    "    print(unique_raw_places[:50])\n",
    "else:\n",
    "    print(\"Error: expanded_noscemus_metadata is not available or empty. Please ensure the 'Expand Multi-Location Rows' cell ran successfully.\")\n",
    "    # Initialize empty to prevent errors in subsequent cells, or handle appropriately\n",
    "    places_series = pd.Series(dtype=str) \n",
    "    unique_raw_places = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3A: Geocode Unique Place Names\n",
    "\n",
    "GEONAMES_USERNAME = \"utaysi\"  # Your Geonames username\n",
    "raw_geocoded_cache_file = 'raw_geocoded_places_cache.csv'\n",
    "\n",
    "def get_coordinates(place_name, username):\n",
    "    if not place_name or pd.isna(place_name):\n",
    "        return None, None, None, None\n",
    "    # Ensure place_name is a string for requests.utils.quote\n",
    "    place_name_str = str(place_name)\n",
    "    try:\n",
    "        # Initial attempt: prioritize populated places (featureClass=P)\n",
    "        url = f\"http://api.geonames.org/searchJSON?q={requests.utils.quote(place_name_str)}&maxRows=1&featureClass=P&username={username}\"\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        data = response.json()\n",
    "        if data.get('geonames') and len(data['geonames']) > 0:\n",
    "            top_result = data['geonames'][0]\n",
    "            return float(top_result['lat']), float(top_result['lng']), top_result.get('name'), top_result.get('countryName')\n",
    "        else:\n",
    "            # Fallback: search without featureClass if no populated place found or if initial result is empty\n",
    "            # This helps with broader terms or historical names that might not be classed as 'P'\n",
    "            url_fallback = f\"http://api.geonames.org/searchJSON?q={requests.utils.quote(place_name_str)}&maxRows=1&username={username}\"\n",
    "            # print(f\"Retrying without featureClass for: {place_name_str}\") # Optional: for debugging\n",
    "            response_fallback = requests.get(url_fallback, timeout=15)\n",
    "            response_fallback.raise_for_status()\n",
    "            data_fallback = response_fallback.json()\n",
    "            if data_fallback.get('geonames') and len(data_fallback['geonames']) > 0:\n",
    "                top_result_fallback = data_fallback['geonames'][0]\n",
    "                # print(f\"Fallback success for {place_name_str}: Found {top_result_fallback.get('name')}\") # Optional\n",
    "                return float(top_result_fallback['lat']), float(top_result_fallback['lng']), top_result_fallback.get('name'), top_result_fallback.get('countryName')\n",
    "            # print(f\"Place not found by Geonames (even after fallback): {place_name_str}\") # Optional\n",
    "            return None, None, None, None\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"API request timed out for {place_name_str}\")\n",
    "        return None, None, None, None\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred for {place_name_str}: {http_err} - Response: {response.text[:200]}...\")\n",
    "        return None, None, None, None\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"API request failed for {place_name_str}: {req_err}\")\n",
    "        return None, None, None, None\n",
    "    except ValueError as json_err: # Handles JSON decoding errors\n",
    "        print(f\"JSON decoding failed for {place_name_str} (response: {response.text[:200]}...): {json_err}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Check for cached data first\n",
    "if os.path.exists(raw_geocoded_cache_file):\n",
    "    print(f\"Loading raw geocoded data from cache: {raw_geocoded_cache_file}\")\n",
    "    raw_geocoded_df = pd.read_csv(raw_geocoded_cache_file)\n",
    "    # Ensure all expected columns are present, fill with NA if not\n",
    "    expected_cols = ['raw_place', 'geoname_name', 'latitude', 'longitude', 'country']\n",
    "    for col in expected_cols:\n",
    "        if col not in raw_geocoded_df.columns:\n",
    "            raw_geocoded_df[col] = pd.NA\n",
    "else:\n",
    "    print(f\"No cache file found ({raw_geocoded_cache_file}). Geocoding raw places...\")\n",
    "    raw_geocoded_data = []\n",
    "    if 'places_series' in locals():\n",
    "        unique_raw_places = places_series.dropna().unique() # Use dropna() before unique()\n",
    "        print(f\"Geocoding {len(unique_raw_places)} unique raw place names...\")\n",
    "        for i, place in enumerate(unique_raw_places):\n",
    "            if str(place).strip() == \"nan\" or str(place).strip() == \"\": # Skip if place is 'nan' string or empty after strip\n",
    "                # print(f\"Skipping invalid place entry: '{place}'\") # Optional\n",
    "                lat, lon, geoname_name, country = None, None, None, None\n",
    "            else:\n",
    "                if (i+1) % 20 == 0:\n",
    "                    print(f\"Processed {i+1}/{len(unique_raw_places)} places...\")\n",
    "                lat, lon, geoname_name, country = get_coordinates(place, GEONAMES_USERNAME)\n",
    "            \n",
    "            raw_geocoded_data.append({'raw_place': place, \n",
    "                                      'geoname_name': geoname_name, \n",
    "                                      'latitude': lat, \n",
    "                                      'longitude': lon, \n",
    "                                      'country': country})\n",
    "            time.sleep(0.1) # 100ms delay to be respectful to the API\n",
    "\n",
    "        raw_geocoded_df = pd.DataFrame(raw_geocoded_data)\n",
    "        raw_geocoded_df.to_csv(raw_geocoded_cache_file, index=False)\n",
    "        print(f\"Saved raw geocoded data to cache: {raw_geocoded_cache_file}\")\n",
    "    else:\n",
    "        print(\"Error: 'places_series' not defined. Please ensure the previous cells (especially 'cline_extract_place_column') have been run.\")\n",
    "        raw_geocoded_df = pd.DataFrame(columns=['raw_place', 'geoname_name', 'latitude', 'longitude', 'country']) # Create empty df\n",
    "\n",
    "if not raw_geocoded_df.empty:\n",
    "    print(f\"\\nSuccessfully geocoded {raw_geocoded_df['latitude'].notna().sum()} places out of {len(raw_geocoded_df)} unique raw names processed.\")\n",
    "    print(\"\\nSample of geocoded data (first 20 rows):\")\n",
    "    print(raw_geocoded_df.head(20))\n",
    "    \n",
    "    print(\"\\nPlaces that were NOT found by Geonames (sample):\")\n",
    "    not_found_sample = raw_geocoded_df[raw_geocoded_df['latitude'].isna()]['raw_place'].unique()\n",
    "    print(not_found_sample[:20]) # Show up to 20 unique not found raw places\n",
    "    print(f\"Total unique raw places not found: {len(not_found_sample)}\")\n",
    "else:\n",
    "    print(\"\\nraw_geocoded_df is empty. Check for errors in previous steps or API calls.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4A: Merge Geocoded Data with Expanded Metadata\n",
    "\n",
    "# Ensure both DataFrames are loaded and available\n",
    "if 'expanded_noscemus_metadata' in locals() and 'raw_geocoded_df' in locals():\n",
    "    if not expanded_noscemus_metadata.empty and not raw_geocoded_df.empty:\n",
    "        # Merge the geocoded data (lat, lon) back into the expanded metadata\n",
    "        # The 'Place' column in expanded_noscemus_metadata should match 'raw_place' in raw_geocoded_df\n",
    "        metadata_with_coords = pd.merge(\n",
    "            expanded_noscemus_metadata,\n",
    "            raw_geocoded_df[['raw_place', 'latitude', 'longitude', 'geoname_name', 'country']],\n",
    "            left_on='Place',\n",
    "            right_on='raw_place',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Drop the redundant 'raw_place' column if it's different from 'Place' or just to clean up\n",
    "        if 'raw_place' in metadata_with_coords.columns and 'Place' in metadata_with_coords.columns:\n",
    "             metadata_with_coords.drop(columns=['raw_place'], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "        print(f\"Successfully merged geocoded data. New DataFrame 'metadata_with_coords' has {len(metadata_with_coords)} rows.\")\n",
    "        print(f\"Number of entries with valid coordinates: {metadata_with_coords['latitude'].notna().sum()}\")\n",
    "        \n",
    "        print(\"\\nSample of merged data (first 5 rows with coordinates):\")\n",
    "        print(metadata_with_coords[metadata_with_coords['latitude'].notna()][['id', 'Full title', 'Place', 'file_year', 'latitude', 'longitude', 'geoname_name']].head())\n",
    "        \n",
    "        print(\"\\nSample of entries that might be missing coordinates (if any):\")\n",
    "        print(metadata_with_coords[metadata_with_coords['latitude'].isna()][['id', 'Full title', 'Place']].head())\n",
    "    else:\n",
    "        print(\"Error: One or both DataFrames (expanded_noscemus_metadata, raw_geocoded_df) are empty.\")\n",
    "        metadata_with_coords = pd.DataFrame() # Initialize empty to avoid errors\n",
    "else:\n",
    "    print(\"Error: 'expanded_noscemus_metadata' or 'raw_geocoded_df' not found. Please ensure previous cells ran successfully.\")\n",
    "    metadata_with_coords = pd.DataFrame() # Initialize empty to avoid errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4B: Create Interactive Map with Folium (Part 1: Pinpoints)\n",
    "\n",
    "if 'metadata_with_coords' in locals() and not metadata_with_coords.empty:\n",
    "    # Filter out rows where latitude or longitude is missing\n",
    "    map_data = metadata_with_coords.dropna(subset=['latitude', 'longitude'])\n",
    "    \n",
    "    if not map_data.empty:\n",
    "        print(f\"Plotting {len(map_data)} works on the map.\")\n",
    "        \n",
    "        # Create a Folium map centered on Europe\n",
    "        # Adjust location and zoom_start as needed\n",
    "        europe_center = [50, 15] # Latitude, Longitude for a general Europe center\n",
    "        interactive_map_part1 = folium.Map(location=europe_center, zoom_start=4)\n",
    "\n",
    "        # Add markers for each work\n",
    "        for idx, row in map_data.iterrows():\n",
    "            # Prepare popup text\n",
    "            # Ensure all components of popup are strings and handle potential NaNs\n",
    "            title = str(row['Full title']) if pd.notna(row['Full title']) else \"N/A\"\n",
    "            place = str(row['Place']) if pd.notna(row['Place']) else \"N/A\"\n",
    "            year = str(int(row['file_year'])) if pd.notna(row['file_year']) else \"N/A\"\n",
    "            \n",
    "            popup_html = f\"\"\"\n",
    "            <b>Title:</b> {title}<br>\n",
    "            <b>Place:</b> {place}<br>\n",
    "            <b>Year:</b> {year}<br>\n",
    "            <b>Lat/Lon:</b> {row['latitude']:.2f}, {row['longitude']:.2f}\n",
    "            \"\"\"\n",
    "            iframe = folium.IFrame(popup_html, width=300, height=100)\n",
    "            popup = folium.Popup(iframe, max_width=300)\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                radius=5, # Small circle marker\n",
    "                popup=popup,\n",
    "                tooltip=f\"{title[:50]}... ({place})\", # Shorter tooltip\n",
    "                color='blue',\n",
    "                fill=True,\n",
    "                fill_color='blue',\n",
    "                fill_opacity=0.6\n",
    "            ).add_to(interactive_map_part1)\n",
    "\n",
    "        # Display the map\n",
    "        # In a Jupyter Notebook, the map object itself will render when it's the last expression in a cell\n",
    "        print(\"Map generation complete. The map should display below.\")\n",
    "        # interactive_map_part1 # This line will display the map\n",
    "    else:\n",
    "        print(\"No data with valid coordinates available to plot on the map.\")\n",
    "else:\n",
    "    print(\"Error: 'metadata_with_coords' DataFrame not found or is empty. Please run the previous cell (Phase 4A).\")\n",
    "\n",
    "# To display the map, ensure this cell's last line is 'interactive_map_part1' (uncommented if necessary)\n",
    "# For now, let's assign it to a variable and then explicitly call it to ensure it's the last thing.\n",
    "if 'interactive_map_part1' in locals():\n",
    "    from IPython.display import display # Make sure display is imported\n",
    "    display(interactive_map_part1)\n",
    "elif 'map_data' in locals() and map_data.empty:\n",
    "    print(\"Map not generated as there was no data to plot.\")\n",
    "else:\n",
    "    print(\"Map object 'interactive_map_part1' was not created, likely due to an error in the preceding logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4C: Prepare Data for Time Slider\n",
    "\n",
    "if 'metadata_with_coords' in locals() and not metadata_with_coords.empty:\n",
    "    print(\"Preparing data for time-slider map...\")\n",
    "    # Make a copy to avoid modifying the original DataFrame used by other maps\n",
    "    map_data_for_time = metadata_with_coords.copy()\n",
    "\n",
    "    # Clean 'file_year': convert to numeric, coercing errors to NaT/NaN\n",
    "    map_data_for_time['file_year_numeric'] = pd.to_numeric(map_data_for_time['file_year'], errors='coerce')\n",
    "\n",
    "    # Drop rows where 'file_year_numeric' is NaN (i.e., couldn't be converted or was originally NaN)\n",
    "    # Also ensure latitude and longitude are present\n",
    "    original_rows = len(map_data_for_time)\n",
    "    map_data_cleaned_time = map_data_for_time.dropna(subset=['file_year_numeric', 'latitude', 'longitude'])\n",
    "    dropped_rows = original_rows - len(map_data_cleaned_time)\n",
    "    print(f\"Dropped {dropped_rows} rows due to missing/invalid year or missing coordinates.\")\n",
    "\n",
    "    if not map_data_cleaned_time.empty:\n",
    "        # Convert 'file_year_numeric' to integer\n",
    "        map_data_cleaned_time.loc[:, 'file_year_numeric'] = map_data_cleaned_time['file_year_numeric'].astype(int)\n",
    "        \n",
    "        min_year = map_data_cleaned_time['file_year_numeric'].min()\n",
    "        max_year = map_data_cleaned_time['file_year_numeric'].max()\n",
    "        print(f\"Data prepared for time slider: {len(map_data_cleaned_time)} entries.\")\n",
    "        print(f\"Year range in data: {min_year} - {max_year}\")\n",
    "        \n",
    "        # Display a sample of the cleaned data\n",
    "        print(\"\\nSample of cleaned data for time slider (first 5 rows):\")\n",
    "        print(map_data_cleaned_time[['id', 'Full title', 'Place', 'file_year_numeric', 'latitude', 'longitude']].head())\n",
    "    else:\n",
    "        print(\"No valid data remaining after cleaning for the time slider.\")\n",
    "        # Ensure map_data_cleaned_time exists as an empty DataFrame if all rows were dropped\n",
    "        map_data_cleaned_time = pd.DataFrame(columns=map_data_for_time.columns.tolist() + ['file_year_numeric'])\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'metadata_with_coords' DataFrame not found or is empty. Please run Phase 4A first.\")\n",
    "    # Initialize map_data_cleaned_time as an empty DataFrame to prevent errors in the next cell\n",
    "    map_data_cleaned_time = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4D: Interactive Map with ipywidgets Year Range Input (Enter to Update)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import folium # Ensure folium is imported\n",
    "\n",
    "if 'map_data_cleaned_time' in locals() and not map_data_cleaned_time.empty:\n",
    "    \n",
    "    min_data_year = int(map_data_cleaned_time['file_year_numeric'].min())\n",
    "    max_data_year = int(map_data_cleaned_time['file_year_numeric'].max())\n",
    "\n",
    "    print(f\"Full data year range available: {min_data_year} - {max_data_year}\")\n",
    "    print(\"Enter start and end years, then press Enter in either box to update the map.\")\n",
    "\n",
    "    # Output widget to display the map\n",
    "    map_output = widgets.Output()\n",
    "    # Output widget for messages (e.g., validation errors)\n",
    "    message_output = widgets.Output()\n",
    "\n",
    "    # Define input widgets\n",
    "    start_year_input = widgets.IntText(\n",
    "        value=min_data_year,\n",
    "        description='Start Year:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    end_year_input = widgets.IntText(\n",
    "        value=min_data_year + 9, # Default to a 10-year span\n",
    "        description='End Year:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Store the current map to avoid re-rendering if inputs are invalid\n",
    "    # This variable needs to be accessible by handle_submit, \n",
    "    # and since handle_submit is defined in the same scope, it is.\n",
    "    current_map_display = None \n",
    "\n",
    "    def handle_submit(widget): # Can be triggered by IntText's on_submit\n",
    "        # Access global current_map_display if we need to modify it and it's outside.\n",
    "        # However, it's better to pass it or make it an attribute of a class if state becomes complex.\n",
    "        # For this function, we can rely on Python's LEGB rule if current_map_display is in the same or enclosing scope.\n",
    "        # To be explicit and ensure we modify the one in the outer scope if it were nested deeper:\n",
    "        # global current_map_display # Not needed here as it's in the same scope.\n",
    "        nonlocal current_map_display # Declare we are modifying the outer scoped current_map_display\n",
    "\n",
    "        with message_output:\n",
    "            clear_output() # Clear previous messages\n",
    "            \n",
    "            s_year = start_year_input.value\n",
    "            e_year = end_year_input.value\n",
    "\n",
    "            valid_input = True\n",
    "            if not (isinstance(s_year, int) and isinstance(e_year, int)):\n",
    "                print(\"Error: Start and End years must be integers.\")\n",
    "                valid_input = False\n",
    "            elif s_year > e_year:\n",
    "                print(\"Error: Start Year cannot be greater than End Year.\")\n",
    "                valid_input = False\n",
    "            \n",
    "            if valid_input and (s_year < min_data_year or e_year > max_data_year):\n",
    "                # This is a warning, not an error that prevents map update\n",
    "                print(f\"Warning: Specified range ({s_year}-{e_year}) is partially outside available data range ({min_data_year}-{max_data_year}).\")\n",
    "\n",
    "            if not valid_input:\n",
    "                # If inputs are invalid, re-display the last valid map or an empty one if none\n",
    "                with map_output:\n",
    "                    clear_output(wait=True)\n",
    "                    # No need to display current_map_display here, just prevent update.\n",
    "                    # The user will see the error in message_output and the map_output will retain its last state.\n",
    "                    # If current_map_display was used, it would re-display the old map, which might be confusing with the error.\n",
    "                    # Let's just print a message in map_output if it's the first run and invalid.\n",
    "                    if not current_map_display: # Only if it's the very first attempt and it's invalid\n",
    "                         print(\"Please enter a valid year range to display the map.\")\n",
    "                return\n",
    "            \n",
    "        # Proceed to update map if inputs are valid\n",
    "        # This section is reached only if valid_input is True\n",
    "        with map_output:\n",
    "            clear_output(wait=True) # Clear previous map\n",
    "            \n",
    "            print(f\"Filtering for years: {s_year} - {e_year}\")\n",
    "            \n",
    "            window_data = map_data_cleaned_time[\n",
    "                (map_data_cleaned_time['file_year_numeric'] >= s_year) &\n",
    "                (map_data_cleaned_time['file_year_numeric'] <= e_year)\n",
    "            ]\n",
    "            \n",
    "            print(f\"Found {len(window_data)} works in this year range.\")\n",
    "\n",
    "            europe_center = [50, 15]\n",
    "            interactive_map_range = folium.Map(location=europe_center, zoom_start=4)\n",
    "\n",
    "            if not window_data.empty:\n",
    "                for idx, row in window_data.iterrows():\n",
    "                    title = str(row['Full title']) if pd.notna(row['Full title']) else \"N/A\"\n",
    "                    place = str(row['Place']) if pd.notna(row['Place']) else \"N/A\"\n",
    "                    year = str(int(row['file_year_numeric']))\n",
    "\n",
    "                    popup_html = f\"\"\"\n",
    "                    <b>Title:</b> {title}<br>\n",
    "                    <b>Place:</b> {place}<br>\n",
    "                    <b>Year:</b> {year}<br>\n",
    "                    <b>Lat/Lon:</b> {row['latitude']:.2f}, {row['longitude']:.2f}\n",
    "                    \"\"\"\n",
    "                    popup = folium.Popup(popup_html, max_width=300)\n",
    "                    \n",
    "                    folium.CircleMarker(\n",
    "                        location=[row['latitude'], row['longitude']],\n",
    "                        radius=5,\n",
    "                        popup=popup,\n",
    "                        tooltip=f\"{title[:50]}... ({place}, {year})\",\n",
    "                        color='darkblue', \n",
    "                        fill=True,\n",
    "                        fill_color='darkblue',\n",
    "                        fill_opacity=0.7\n",
    "                    ).add_to(interactive_map_range)\n",
    "                \n",
    "                current_map_display = interactive_map_range \n",
    "                display(interactive_map_range)\n",
    "            else:\n",
    "                print(\"No works found for the selected year range.\")\n",
    "                current_map_display = interactive_map_range \n",
    "                display(interactive_map_range) \n",
    "    \n",
    "    start_year_input.on_submit(handle_submit)\n",
    "    end_year_input.on_submit(handle_submit)\n",
    "\n",
    "    input_widgets = widgets.HBox([start_year_input, end_year_input])\n",
    "    \n",
    "    display(input_widgets)\n",
    "    display(message_output) \n",
    "    display(map_output)\n",
    "    \n",
    "    handle_submit(None)\n",
    "\n",
    "\n",
    "elif 'map_data_cleaned_time' in locals() and map_data_cleaned_time.empty:\n",
    "    print(\"Map controls not generated as there was no cleaned data to plot (map_data_cleaned_time is empty).\")\n",
    "else:\n",
    "    print(\"Error: 'map_data_cleaned_time' DataFrame not found. Please run Phase 4C first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0183f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

</final_file_content>

IMPORTANT: For any future changes to this file, use the final_file_content shown above as your reference. This content reflects the current state of the file, including any auto-formatting (e.g., if you used single quotes but the formatter converted them to double quotes). Always base your SEARCH/REPLACE operations on this final version to ensure accuracy.

<environment_details>
# VSCode Visible Files
NOSCEMUS_geomapping.ipynb
NOSCEMUS_geomapping.ipynb

# VSCode Open Tabs
NOSCEMUS_geomapping.ipynb
NOSCEMUS_geomapping.ipynb
ipynb-json.json

# Current Time
5/23/2025, 2:17:35 PM (Europe/Berlin, UTC+2:00)

# Context Window Usage
305,273 / 1,048.576K tokens used (29%)

# Current Mode
ACT MODE
</environment_details>
